# Byte-compiled / optimized / DLL files
__pycache__/
*.py[cod]
*$py.class

# C extensions
*.so

# Distribution / packaging
.Python
env/
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
*.egg-info/
.installed.cfg
*.egg

# PyInstaller
#  Usually these files are written by a python script from a template
#  before PyInstaller builds the exe, so as to inject date/other infos into it.
*.manifest
*.spec

# Installer logs
pip-log.txt
pip-delete-this-directory.txt

# Unit test / coverage reports
htmlcov/
.tox/
.coverage
.coverage.*
.cache
nosetests.xml
coverage.xml
*,cover
.hypothesis/

# Translations
*.mo
*.pot

# Django stuff:
*.log
local_settings.py

# Flask stuff:
instance/
.webassets-cache

# Scrapy stuff:
.scrapy

# Sphinx documentation
docs/_build/

# PyBuilder
target/

# IPython Notebook
.ipynb_checkpoints

# pyenv
.python-version

# celery beat schedule file
celerybeat-schedule

# dotenv
.env

# virtualenv
venv/
ENV/

# Spyder project settings
.spyderproject

# Rope project settings
.ropeproject

import re
import requests

item_price = open('price.txt', 'a')
with open('url_file.txt') as f:
    url = f.read().strip().split(',')
header = {'User-Agent':'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36',
          'Connection':'keep-alive',
                    }
i = 0
for i in range(52):
    if i < 52:
        page_url = requests.get(url[i], headers=header)
        page = page_url.text
        price = re.findall('<span id="priceblock_saleprice" class="a-size-medium a-color-price"(.*?)</span>', page, re.S)
        print(price, file=item_price)
    else:
        print('Finish')
        
html = urlopen('https://www.amazon.com/dp/B00CRR5L8U')
bsobj = BeautifulSoup(html, "html.parser")
price = bsobj.findAll('span', {'id': 'priceblock_saleprice'})
print(price[0].get_text())
